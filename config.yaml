env_config:
  inputfile: '' #Gets populated on runtime
  obs_type: image
  Loglevel: 0
  width: 84 #84
  height: 84 #84
  maxMF_Elements: 4
  outputScale: 2 #10
  render_mode: null
  factoryconfig: SMALLSQUARE
  prefix: null #Gets populated on runtime
  evaluation: false #Gets populated on runtime
  reward_function: 2
  randomSeed: null
  createMachines: true


# Evaluate once per training iteration.
evaluation_interval: 1
# Run evaluation on (at least) ten episodes
evaluation_duration: 50
# ... using one evaluation worker (setting this to 0 will cause
# evaluation to run on the local evaluation worker, blocking
# training until evaluation is done).
evaluation_num_workers: 2

# Special evaluation config. Keys specified here will override
# the same keys in the main config, but only for evaluation.
evaluation_config:
# Store videos in this relative directory here inside
# the default output dir (~/ray_results/...).
# Alternatively, you can specify an absolute path.
# Set to True for using the default output dir (~/ray_results/...).
# Set to False for not recording anything.
#"record_env": os.path.join(os.path.dirname(os.path.realpath(__file__)), "Output"),
# Render the env while evaluating.
# Note that this will always only render the 1st RolloutWorker's
# env and only the 1st sub-env in a vectorized env.
  render_env: false
  env_config:
    Loglevel: 0
    width: 84 #84
    height: 84 #84
    maxMF_Elements: 5
    outputScale: 2 #10
    render_mode: rgb_array
    factoryconfig: SMALLSQUARE
    prefix: null #Gets populated on runtime
    evaluation: true
    randomSeed: 42
    reward_function: 2
    createMachines: false

render_env: false
num_workers: 1  # parallelism  #12
num_envs_per_env_runner: 1

# Should be one of DEBUG, INFO, WARN, or ERROR
log_level: ERROR
# Whether - upon a worker failure - RLlib will try to recreate the lost worker as
# an identical copy of the failed one. The new worker will only differ from the
# failed one in its `self.recreated_worker=True` property value. It will have
# the same `worker_index` as the original one.
# If True, the `ignore_worker_failures` setting will be ignored.
recreate_failed_workers: true
restart_failed_sub_environments: true

rollout_fragment_length: 200
train_batch_size:  200 #3200
sgd_minibatch_size: 100
num_sgd_iter: 4
gamma: 0.99
# The default learning rate.
lr: 0.00025  #0.00002,
lambda: 0.95
vf_loss_coeff: 0.5
entropy_coeff: 0.01
clip_param: 0.2
vf_clip_param: 10.0
kl_target: 0.01
