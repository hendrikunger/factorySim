env_config:
  inputfile: '' #Gets populated on runtime
  obs_type: image
  Loglevel: 0
  width: 84 #84
  height: 84 #84
  maxMF_Elements: 0
  outputScale: 2 #10
  render_mode: null
  factoryconfig: SMALLSQUARE
  prefix: null #Gets populated on runtime
  evaluation: false #Gets populated on runtime
  reward_function: 3
  randomSeed: null
  createMachines: true
  logLevel: 0



# Evaluate once per training iteration.
evaluation_interval: 1
training_iteration: 4 # Number of training iterations to run.

# Special evaluation config. Keys specified here will override
# the same keys in the main config, but only for evaluation.
evaluation_config:
# Store videos in this relative directory here inside
# the default output dir (~/ray_results/...).
# Alternatively, you can specify an absolute path.
# Set to True for using the default output dir (~/ray_results/...).
# Set to False for not recording anything.
#"record_env": os.path.join(os.path.dirname(os.path.realpath(__file__)), "Output"),
# Render the env while evaluating.
# Note that this will always only render the 1st RolloutWorker's
# env and only the 1st sub-env in a vectorized env.
  render_env: false
  env_config:
    inputfile: '' #Gets populated on runtime
    obs_type: image
    Loglevel: 0
    width: 84 #84
    height: 84 #84
    maxMF_Elements: null
    outputScale: 10 #10
    render_mode: rgb_array
    factoryconfig: SMALLSQUARE
    prefix: null #Gets populated on runtime
    evaluation: true
    randomSeed: 42
    reward_function: 3
    createMachines: false
    logLevel: 0


render_env: false
num_workers: 32  # parallelism  #12
num_envs_per_env_runner: 1
evaluation_parallel_to_training: false
evaluation_num_env_runners: 0


# Whether - upon a worker failure - RLlib will try to recreate the lost worker as
# an identical copy of the failed one. The new worker will only differ from the
# failed one in its `self.recreated_worker=True` property value. It will have
# the same `worker_index` as the original one.
# If True, the `ignore_worker_failures` setting will be ignored.
recreate_failed_workers: true
restart_failed_sub_environments: true

rollout_fragment_length: 4000 #4096
train_batch_size_per_learner:  4000 #4096
mini_batch_size_per_learner: 100 #100
num_sgd_iter: 4
gamma: 0.99
# The default learning rate.
lr: 0.00025  #0.00002,
lambda: 0.95
vf_loss_coeff: 0.5
entropy_coeff: 0.01
clip_param: 0.2
vf_clip_param: 10.0
kl_target: 0.01
